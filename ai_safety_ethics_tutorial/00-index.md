# AI Safety, Ethics, and Alignment Tutorial

## Overview
Comprehensive guide to building safe, ethical, and aligned AI systems. Critical for responsible AI development and AGI research.

## Table of Contents

1. **[AI Alignment Problem](01-alignment-problem.md)** - Value alignment, mesa-optimization, inner/outer alignment, specification gaming, reward hacking
2. **[Bias and Fairness](02-bias-fairness.md)** - Bias sources, fairness definitions, detection methods, mitigation strategies, fairness-aware ML
3. **[Adversarial Robustness](03-adversarial-robustness.md)** - Adversarial examples, attacks, defenses, certified robustness, adversarial training
4. **[Interpretability Deep Dive](04-interpretability.md)** - XAI methods, mechanistic interpretability, circuits, probing, concept-based explanations
5. **[Privacy-Preserving ML](05-privacy-preserving-ml.md)** - Differential privacy, federated learning, secure multi-party computation, privacy attacks
6. **[AI Governance](06-ai-governance.md)** - Regulation (EU AI Act), auditing, documentation, model cards, ethical frameworks
7. **[Red Teaming](07-red-teaming.md)** - Adversarial testing, jailbreaking, prompt injection, safety benchmarks, evaluation
8. **[Safe AGI Research](08-safe-agi-research.md)** - AI safety research directions, scalable oversight, debate, recursive reward modeling, RLHF limitations

## Prerequisites
- ML/DL knowledge
- Ethics basics
- Critical thinking

## Tools: Fairlearn, AIF360, CleverHans, Foolbox, privacy tools

## Time: 8-10 weeks

