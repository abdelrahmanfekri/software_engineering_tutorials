# Module 2: Code Generation Fundamentals

**AI Content Generation Prompt:**
Create code generation guide: Seq2seq models for code, Transformer architectures for code, CodeBERT (pretraining, fine-tuning), GraphCodeBERT (structure-aware), Codex architecture, GPT-4 for code, Fine-tuning strategies (LoRA for code models), Evaluation metrics (BLEU, CodeBLEU, pass@k, execution-based), Beam search for code, Sampling strategies, Complete training pipeline, 20 exercises.

Target: 1200-1500 lines with model training code.

