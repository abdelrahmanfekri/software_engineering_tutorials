# Agent App - Modern LLM Agent Application

A production-ready LLM agent application built with Claude, featuring tool calling, web search, code execution, and database queries.

## Features

- ğŸ¤– **Intelligent Agent**: ReAct pattern-based reasoning with Claude
- ğŸ› ï¸ **Tool Ecosystem**: Extensible tool system with web search, code execution, and database queries
- ğŸ’¾ **Memory Management**: Conversation history with context window handling
- ğŸš€ **FastAPI Backend**: RESTful API with async support
- ğŸ“Š **Observability**: Structured logging and tracing
- ğŸ§ª **Tested**: Unit and integration tests
- ğŸ³ **Docker Ready**: Containerized deployment

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI Application        â”‚
â”‚   (API Routes & Middleware)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Agent Core                â”‚
â”‚   (ReAct Loop Orchestration)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM   â”‚    â”‚   Tools    â”‚
â”‚ Client â”‚    â”‚  Registry  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼          â–¼          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Web   â”‚ â”‚  Code  â”‚ â”‚Databaseâ”‚
    â”‚ Search â”‚ â”‚  Exec  â”‚ â”‚ Query  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- Python 3.10+
- Anthropic API key

### Installation

1. Clone the repository:
```bash
git clone <repo-url>
cd agent-app
```

2. Install dependencies:
```bash
pip install -e .
# or with poetry
poetry install
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### Running the Application

#### CLI Mode (Interactive)

```bash
python scripts/run_agent.py
```

This launches an interactive CLI where you can chat with the agent:

```
You: What's 123 * 456?
Agent: Let me calculate that for you...
[Uses execute_code tool]
The result is 56,088.
```

#### API Mode

```bash
# Start the FastAPI server
python -m src.api.main

# Or with uvicorn directly
uvicorn src.api.main:app --reload
```

Then visit `http://localhost:8000/docs` for the interactive API documentation.

### Making API Requests

```bash
# Send a message
curl -X POST "http://localhost:8000/chat/message" \
  -H "Content-Type: application/json" \
  -d '{"message": "Search for recent AI news"}'

# Reset a session
curl -X POST "http://localhost:8000/chat/reset/session_0"

# List active sessions
curl "http://localhost:8000/chat/sessions"
```

## Project Structure

```
agent-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/          # Core agent logic (ReAct loop)
â”‚   â”œâ”€â”€ tools/          # Tool implementations
â”‚   â”œâ”€â”€ llm/            # LLM client wrapper
â”‚   â”œâ”€â”€ memory/         # Conversation memory
â”‚   â”œâ”€â”€ api/            # FastAPI application
â”‚   â””â”€â”€ utils/          # Utilities and config
â”œâ”€â”€ tests/              # Unit and integration tests
â”œâ”€â”€ scripts/            # CLI and utility scripts
â”œâ”€â”€ config/             # Configuration files
â””â”€â”€ docs/               # Documentation
```

## Available Tools

### 1. Web Search
Search the web for current information.
```python
result = await agent.run("What's the latest news about AI?")
```

### 2. Code Execution
Execute Python code for calculations and data processing.
```python
result = await agent.run("Calculate the first 10 Fibonacci numbers")
```

### 3. Database Query
Query database tables with natural language.
```python
result = await agent.run("Show me all users in the database")
```

## Adding Custom Tools

1. Create a new tool class:

```python
from src.tools.base import BaseTool, ToolSchema

class MyCustomTool(BaseTool):
    def get_schema(self) -> ToolSchema:
        return ToolSchema(
            name="my_tool",
            description="Does something useful",
            parameters={
                "type": "object",
                "properties": {
                    "param": {"type": "string"}
                },
                "required": ["param"]
            }
        )
    
    async def execute(self, param: str, **kwargs):
        # Your tool logic here
        return {"result": f"Processed: {param}"}
```

2. Register it:

```python
from src.tools import ToolRegistry
from my_module import MyCustomTool

registry = ToolRegistry()
registry.register(MyCustomTool())
```

## Testing

Run the test suite:

```bash
# All tests
pytest

# With coverage
pytest --cov=src tests/

# Specific test file
pytest tests/unit/test_tools.py

# Verbose mode
pytest -v
```

## Configuration

Environment variables (`.env`):

```bash
# Required
ANTHROPIC_API_KEY=your-key-here

# Optional
MODEL_NAME=claude-sonnet-4-20250514
MAX_ITERATIONS=10
LOG_LEVEL=INFO
```

## Development

### Code Style

```bash
# Format code
black src/ tests/

# Lint
ruff check src/ tests/

# Type check
mypy src/
```

### Project Workflow

1. Create a feature branch
2. Write tests first (TDD)
3. Implement the feature
4. Ensure tests pass
5. Format and lint code
6. Submit PR

## Production Considerations

### Security
- Add authentication middleware
- Validate all tool inputs
- Sandbox code execution properly
- Rate limit API endpoints
- Use secrets management (not .env files)

### Scalability
- Use Redis for session storage
- Implement connection pooling for database
- Add caching layer for LLM responses
- Use message queue for async tool execution

### Monitoring
- Add Prometheus metrics
- Integrate with APM (e.g., DataDog, New Relic)
- Set up alerting for errors
- Track token usage and costs

## Troubleshooting

### Common Issues

**"ModuleNotFoundError"**
- Ensure you're in the project root
- Run `pip install -e .`

**"API key not found"**
- Check `.env` file exists
- Verify `ANTHROPIC_API_KEY` is set

**"Max iterations exceeded"**
- Increase `MAX_ITERATIONS` in config
- Check if agent is stuck in a loop

## License

MIT

## Contributing

Contributions are welcome! Please read CONTRIBUTING.md for guidelines.

## Support

- Documentation: [docs/](docs/)
- Issues: GitHub Issues
- Discussions: GitHub Discussions
